{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary libraries\n",
    "import numpy as np\n",
    "from datasets import load_dataset\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, GRU, Bidirectional, TimeDistributed, Embedding, Dense, Dropout\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CoNLL-2003 dataset\n",
    "dataset = load_dataset('conll2003', trust_remote_code=True)\n",
    "\n",
    "# Extract the train and test data\n",
    "train_data = dataset['train']\n",
    "test_data = dataset['test']\n",
    "\n",
    "# Create a function to extract sentences and labels from the dataset\n",
    "def get_sentences_and_labels(data):\n",
    "    sentences = [\" \".join(x) for x in data['tokens']]\n",
    "    labels = data['ner_tags']\n",
    "    return sentences, labels\n",
    "\n",
    "# Get sentences and labels for training and test data\n",
    "train_sentences, train_labels = get_sentences_and_labels(train_data)\n",
    "test_sentences, test_labels = get_sentences_and_labels(test_data)\n",
    "\n",
    "# Tokenize the sentences, convert them to sequences, and pad the sequences\n",
    "max_len = 50\n",
    "word_tokenizer = tf.keras.preprocessing.text.Tokenizer()\n",
    "word_tokenizer.fit_on_texts(train_sentences)\n",
    "train_sequences = word_tokenizer.texts_to_sequences(train_sentences)\n",
    "test_sequences = word_tokenizer.texts_to_sequences(test_sentences)\n",
    "X_train = pad_sequences(train_sequences, maxlen=max_len, padding='post')\n",
    "X_test = pad_sequences(test_sequences, maxlen=max_len, padding='post')\n",
    "\n",
    "# Encode the training and test labels\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit([item for sublist in train_labels for item in sublist])\n",
    "train_labels_enc = [label_encoder.transform(label) for label in train_labels]\n",
    "test_labels_enc = [label_encoder.transform(label) for label in test_labels]\n",
    "\n",
    "# Pad the training and test labels\n",
    "train_labels_padded = pad_sequences(train_labels_enc, maxlen=max_len, padding='post', value=-1)\n",
    "test_labels_padded = pad_sequences(test_labels_enc, maxlen=max_len, padding='post', value=-1)\n",
    "num_classes = len(label_encoder.classes_) + 1\n",
    "train_labels_onehot = [to_categorical(i, num_classes=num_classes) for i in train_labels_padded]\n",
    "test_labels_onehot = [to_categorical(i, num_classes=num_classes) for i in test_labels_padded]\n",
    "y_train = np.array(train_labels_onehot)\n",
    "y_test = np.array(test_labels_onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 1 - GRU single layer\n",
    "model_1 = Sequential()\n",
    "model_1.add(Embedding(input_dim=len(word_tokenizer.word_index) + 1, output_dim=64, input_length=max_len))\n",
    "model_1.add(GRU(units=64, return_sequences=True))\n",
    "model_1.add(TimeDistributed(Dense(num_classes, activation='softmax')))\n",
    "model_1.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "history_1 = model_1.fit(X_train, y_train, batch_size=32, epochs=10, validation_data=(X_test, y_test))\n",
    "\n",
    "# Model 2 - GRU two layers\n",
    "model_2 = Sequential()\n",
    "model_2.add(Embedding(input_dim=len(word_tokenizer.word_index) + 1, output_dim=64, input_length=max_len))\n",
    "model_2.add(GRU(units=64, return_sequences=True))\n",
    "model_2.add(GRU(units=64, return_sequences=True))\n",
    "model_2.add(TimeDistributed(Dense(num_classes, activation='softmax')))\n",
    "model_2.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "history_2 = model_2.fit(X_train, y_train, batch_size=32, epochs=10, validation_data=(X_test, y_test))\n",
    "\n",
    "# Model 3 - Bidirectional GRU single layer\n",
    "model_3 = Sequential()\n",
    "model_3.add(Embedding(input_dim=len(word_tokenizer.word_index) + 1, output_dim=64, input_length=max_len))\n",
    "model_3.add(Bidirectional(GRU(units=64, return_sequences=True)))\n",
    "model_3.add(TimeDistributed(Dense(num_classes, activation='softmax')))\n",
    "model_3.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "history_3 = model_3.fit(X_train, y_train, batch_size=32, epochs=10, validation_data=(X_test, y_test))\n",
    "\n",
    "# Model 4 - Bidirectional GRU two layers\n",
    "model_4 = Sequential()\n",
    "model_4.add(Embedding(input_dim=len(word_tokenizer.word_index) + 1, output_dim=64, input_length=max_len))\n",
    "model_4.add(Bidirectional(GRU(units=64, return_sequences=True)))\n",
    "model_4.add(Bidirectional(GRU(units=64, return_sequences=True)))\n",
    "model_4.add(TimeDistributed(Dense(num_classes, activation='softmax')))\n",
    "model_4.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "history_4 = model_4.fit(X_train, y_train, batch_size=32, epochs=10, validation_data=(X_test, y_test))\n",
    "\n",
    "# Model 5 - LSTM single layer\n",
    "model_5 = Sequential()\n",
    "model_5.add(Embedding(input_dim=len(word_tokenizer.word_index) + 1, output_dim=64, input_length=max_len))\n",
    "model_5.add(LSTM(units=64, return_sequences=True))\n",
    "model_5.add(TimeDistributed(Dense(num_classes, activation='softmax')))\n",
    "model_5.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "history_5 = model_5.fit(X_train, y_train, batch_size=32, epochs=10, validation_data=(X_test, y_test))\n",
    "\n",
    "# Model 6 - LSTM two layers\n",
    "model_6 = Sequential()\n",
    "model_6.add(Embedding(input_dim=len(word_tokenizer.word_index) + 1, output_dim=64, input_length=max_len))\n",
    "model_6.add(LSTM(units=64, return_sequences=True))\n",
    "model_6.add(LSTM(units=64, return_sequences=True))\n",
    "model_6.add(TimeDistributed(Dense(num_classes, activation='softmax')))\n",
    "model_6.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "history_6 = model_6.fit(X_train, y_train, batch_size=32, epochs=10, validation_data=(X_test, y_test))\n",
    "\n",
    "# Model 7 - Bidirectional LSTM single layer\n",
    "model_7 = Sequential()\n",
    "model_7.add(Embedding(input_dim=len(word_tokenizer.word_index) + 1, output_dim=64, input_length=max_len))\n",
    "model_7.add(Bidirectional(LSTM(units=64, return_sequences=True)))\n",
    "model_7.add(TimeDistributed(Dense(num_classes, activation='softmax')))\n",
    "model_7.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "history_7 = model_7.fit(X_train, y_train, batch_size=32, epochs=10, validation_data=(X_test, y_test))\n",
    "\n",
    "# Model 8 - Bidirectional LSTM two layers\n",
    "model_8 = Sequential()\n",
    "model_8.add(Embedding(input_dim=len(word_tokenizer.word_index) + 1, output_dim=64, input_length=max_len))\n",
    "model_8.add(Bidirectional(LSTM(units=64, return_sequences=True)))\n",
    "model_8.add(Bidirectional(LSTM(units=64, return_sequences=True)))\n",
    "model_8.add(TimeDistributed(Dense(num_classes, activation='softmax')))\n",
    "model_8.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "history_8 = model_8.fit(X_train, y_train, batch_size=32, epochs=10, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to plot the training and validation loss and accuracy\n",
    "def plot_history(history, model_name):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.title(f'{model_name} Model Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend(['Train', 'Val'], loc='upper left')\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title(f'{model_name} Model Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend(['Train', 'Val'], loc='upper left')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Plot the accuracy and loss curves for each model\n",
    "plot_history(history_1, \"Model 1\")\n",
    "plot_history(history_2, \"Model 2\")\n",
    "plot_history(history_3, \"Model 3\")\n",
    "plot_history(history_4, \"Model 4\")\n",
    "plot_history(history_5, \"Model 5\")\n",
    "plot_history(history_6, \"Model 6\")\n",
    "plot_history(history_7, \"Model 7\")\n",
    "plot_history(history_8, \"Model 8\")\n",
    "\n",
    "# Create a function to calculate mean validation accuracy\n",
    "def mean_validation_accuracy(history):\n",
    "    val_acc = history.history['val_accuracy']\n",
    "    mean_acc = np.mean(val_acc)\n",
    "    return mean_acc\n",
    "\n",
    "# Calculate the mean validation accuracy for each model\n",
    "mean_acc_1 = mean_validation_accuracy(history_1)\n",
    "mean_acc_2 = mean_validation_accuracy(history_2)\n",
    "mean_acc_3 = mean_validation_accuracy(history_3)\n",
    "mean_acc_4 = mean_validation_accuracy(history_4)\n",
    "mean_acc_5 = mean_validation_accuracy(history_5)\n",
    "mean_acc_6 = mean_validation_accuracy(history_6)\n",
    "mean_acc_7 = mean_validation_accuracy(history_7)\n",
    "mean_acc_8 = mean_validation_accuracy(history_8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print mean validation accuracies for each model\n",
    "print(f\"Mean Validation Accuracy - Model 1: {mean_acc_1:.4f}\")\n",
    "print(f\"Mean Validation Accuracy - Model 2: {mean_acc_2:.4f}\")\n",
    "print(f\"Mean Validation Accuracy - Model 3: {mean_acc_3:.4f}\")\n",
    "print(f\"Mean Validation Accuracy - Model 4: {mean_acc_4:.4f}\")\n",
    "print(f\"Mean Validation Accuracy - Model 5: {mean_acc_5:.4f}\")\n",
    "print(f\"Mean Validation Accuracy - Model 6: {mean_acc_6:.4f}\")\n",
    "print(f\"Mean Validation Accuracy - Model 7: {mean_acc_7:.4f}\")\n",
    "print(f\"Mean Validation Accuracy - Model 8: {mean_acc_8:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
