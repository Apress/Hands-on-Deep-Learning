{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7qR3pfPGSjgR"
      },
      "outputs": [],
      "source": [
        "# Import the necessary libraries\n",
        "import cv2\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a function to build an autoencoder\n",
        "def build_autoencoder(input_dim, hidden_dim):\n",
        "    # Input layer\n",
        "    input_layer = layers.Input(shape=(input_dim,))\n",
        "    # Encoding layer\n",
        "    encoded = layers.Dense(hidden_dim, activation='relu', name='encoder')(input_layer)\n",
        "    # Decoding layer\n",
        "    decoded = layers.Dense(input_dim, activation='sigmoid')(encoded)\n",
        "    # Creating autoencoder model\n",
        "    autoencoder = keras.Model(input_layer, decoded)\n",
        "    # Compiling the model\n",
        "    autoencoder.compile(optimizer='adam', loss='mse')\n",
        "    # Displaying the model summary\n",
        "    autoencoder.summary()\n",
        "    return autoencoder"
      ],
      "metadata": {
        "id": "mr_dkB63Sq5D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount the Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "Nlqhbm6dT3pA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading the imaging dataset\n",
        "data = np.load('/content/drive/MyDrive/Emotion Detection/X_test_Happy.npy')\n",
        "print(data.shape)\n",
        "# Flattening the images\n",
        "data = data.reshape((len(data), np.prod(data.shape[1:])))\n",
        "print(data.shape)"
      ],
      "metadata": {
        "id": "OKAwlIkUSwlO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Choose the size of hidden dimensions and train the model\n",
        "hidden_dims = [1024, 512]\n",
        "encoder_model = None\n",
        "for i, hidden_dim in enumerate(hidden_dims):\n",
        "    if i == 0:\n",
        "        # Building the initial autoencoder model\n",
        "        autoencoder = build_autoencoder(data.shape[1], hidden_dim)\n",
        "    else:\n",
        "        # Building subsequent autoencoder models with previous encoder output as input\n",
        "        autoencoder = build_autoencoder(encoder_model.output_shape[1], hidden_dim)\n",
        "    # Training the autoencoder model\n",
        "    autoencoder.fit(data, data, epochs=10, batch_size=32)\n",
        "    # Creating encoder model to get the encoded output\n",
        "    encoder_model = keras.Model(autoencoder.input, autoencoder.get_layer('encoder').output)\n",
        "    # Encoding the data\n",
        "    data = encoder_model.predict(data)\n",
        "    final_encoder = encoder_model\n",
        "print(data.shape)"
      ],
      "metadata": {
        "id": "xOejeqTLS4gL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}